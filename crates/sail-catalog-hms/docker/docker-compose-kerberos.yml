version: '3.8'

# Complete Kerberos + HMS + PySpark Testing Environment
#
# This setup provides:
# - MIT Kerberos KDC
# - HMS with Kerberos authentication
# - PostgreSQL backend for HMS
# - PySpark client with keytabs
# - MinIO for S3-compatible storage
#
# Usage:
#   docker-compose -f docker-compose-kerberos.yml up -d
#   docker-compose -f docker-compose-kerberos.yml run pyspark-client

services:
  # MIT Kerberos KDC
  kdc:
    image: gcavalcante8808/krb5-server:latest
    container_name: hms-kdc
    hostname: kdc.example.com
    environment:
      KRB5_REALM: EXAMPLE.COM
      KRB5_KDC: kdc.example.com
      KRB5_PASS: krbpass
    ports:
      - "88:88"
      - "749:749"
    volumes:
      - kdc-data:/var/kerberos/krb5kdc
      - keytabs:/keytabs
      - ./kerberos-init.sh:/docker-entrypoint-initdb.d/init.sh:ro
    networks:
      hms-kerb-network:
        aliases:
          - kdc.example.com
    healthcheck:
      test: ["CMD", "kadmin.local", "-q", "listprincs"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # PostgreSQL backend for HMS
  postgres:
    image: postgres:15-alpine
    container_name: hms-postgres-kerb
    hostname: postgres.example.com
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hive
    ports:
      - "5432:5432"
    volumes:
      - postgres-data-kerb:/var/lib/postgresql/data
    networks:
      hms-kerb-network:
        aliases:
          - postgres.example.com
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "hive"]
      interval: 5s
      timeout: 3s
      retries: 5

  # HMS with Kerberos authentication
  hms-kerb:
    image: apache/hive:3.1.3
    container_name: hms-kerberized
    hostname: hms.example.com
    depends_on:
      kdc:
        condition: service_healthy
      postgres:
        condition: service_healthy
    environment:
      SERVICE_NAME: metastore
      DB_DRIVER: postgres
      # Kerberos configuration
      HADOOP_OPTS: >-
        -Djava.security.krb5.conf=/etc/krb5.conf
        -Dsun.security.krb5.debug=true
      SERVICE_OPTS: >-
        -Djavax.jdo.option.ConnectionDriverName=org.postgresql.Driver
        -Djavax.jdo.option.ConnectionURL=jdbc:postgresql://postgres.example.com:5432/metastore
        -Djavax.jdo.option.ConnectionUserName=hive
        -Djavax.jdo.option.ConnectionPassword=hive
        -Dhive.metastore.sasl.enabled=true
        -Dhive.metastore.kerberos.keytab.file=/etc/security/keytabs/hive.keytab
        -Dhive.metastore.kerberos.principal=hive/hms.example.com@EXAMPLE.COM
        -Dhive.metastore.warehouse.dir=/warehouse
    ports:
      - "9083:9083"
    volumes:
      - hms-warehouse-kerb:/warehouse
      - ./krb5.conf:/etc/krb5.conf:ro
      - keytabs:/etc/security/keytabs:ro
      - ./hive-site-kerberos.xml:/opt/hive/conf/hive-site.xml:ro
    networks:
      hms-kerb-network:
        aliases:
          - hms.example.com
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9083"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 60s

  # MinIO for S3-compatible object storage
  minio:
    image: minio/minio:latest
    container_name: hms-minio-kerb
    hostname: minio.example.com
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data-kerb:/data
    networks:
      hms-kerb-network:
        aliases:
          - minio.example.com
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5

  # PySpark test client with Kerberos
  pyspark-client:
    build:
      context: .
      dockerfile: Dockerfile.pyspark-kerb
    container_name: pyspark-client-kerb
    hostname: client.example.com
    depends_on:
      kdc:
        condition: service_healthy
      hms-kerb:
        condition: service_healthy
      minio:
        condition: service_healthy
    environment:
      # Kerberos configuration
      KRB5_CONFIG: /etc/krb5.conf
      KRB5_CLIENT_KTNAME: /etc/security/keytabs/client.keytab
      # Spark configuration
      SPARK_HOME: /opt/spark
      PYSPARK_PYTHON: python3
      # HMS configuration
      HMS_URI: thrift://hms.example.com:9083
      # MinIO configuration
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_ENDPOINT: http://minio.example.com:9000
    volumes:
      - ./krb5.conf:/etc/krb5.conf:ro
      - keytabs:/etc/security/keytabs:ro
      - ./pyspark-tests:/tests:ro
      - ./test-results:/test-results
    networks:
      hms-kerb-network:
        aliases:
          - client.example.com
    command: ["tail", "-f", "/dev/null"]  # Keep container running

  # Test runner (runs PySpark tests and exits)
  test-runner:
    build:
      context: .
      dockerfile: Dockerfile.pyspark-kerb
    container_name: test-runner
    hostname: test-runner.example.com
    depends_on:
      kdc:
        condition: service_healthy
      hms-kerb:
        condition: service_healthy
      minio:
        condition: service_healthy
    environment:
      KRB5_CONFIG: /etc/krb5.conf
      KRB5_CLIENT_KTNAME: /etc/security/keytabs/client.keytab
      SPARK_HOME: /opt/spark
      PYSPARK_PYTHON: python3
      HMS_URI: thrift://hms.example.com:9083
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin
      AWS_ENDPOINT: http://minio.example.com:9000
    volumes:
      - ./krb5.conf:/etc/krb5.conf:ro
      - keytabs:/etc/security/keytabs:ro
      - ./pyspark-tests:/tests:ro
      - ./test-results:/test-results
    networks:
      hms-kerb-network:
        aliases:
          - test-runner.example.com
    command: ["/tests/run-all-tests.sh"]

volumes:
  kdc-data:
    driver: local
  keytabs:
    driver: local
  postgres-data-kerb:
    driver: local
  hms-warehouse-kerb:
    driver: local
  minio-data-kerb:
    driver: local

networks:
  hms-kerb-network:
    driver: bridge
